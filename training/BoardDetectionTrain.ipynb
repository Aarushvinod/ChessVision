{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iil0J4nTHHb_"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fM1JmUCQLdKp"
      },
      "outputs": [],
      "source": [
        "!git clone --branch v0.6 https://github.com/facebookresearch/detectron2.git detectron2_repo\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install zipfile36"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqCNglJXRro5"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIEKfPKFmW54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.projects import point_rend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grFIdy8ynP-7"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "API_KEY = \"Insert your API Key here\"\n",
        "rf = Roboflow(api_key=API_KEY)\n",
        "project = rf.workspace(\"senior-research-project-3n9r5\").project(\"board-polygon-detection\")\n",
        "version = project.version(10)\n",
        "dataset = version.download(\"coco-segmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbI2PNEZF3sU"
      },
      "outputs": [],
      "source": [
        "#Check dataset\n",
        "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
        "print(DATA_SET_NAME)\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jntOI8GJG2ks"
      },
      "outputs": [],
      "source": [
        "#To use datasets in Detectron2, you first need to register them as such\n",
        "# TRAIN SET\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}_train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    TRAIN_DATA_SET_NAME,\n",
        "    {},\n",
        "    TRAIN_DATA_SET_ANN_FILE_PATH,\n",
        "    TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# TEST SET\n",
        "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}_test\"\n",
        "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n",
        "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    TEST_DATA_SET_NAME,\n",
        "    {},\n",
        "    TEST_DATA_SET_ANN_FILE_PATH,\n",
        "    TEST_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# VALID SET\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}_valid\"\n",
        "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
        "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    VALID_DATA_SET_NAME,\n",
        "    {},\n",
        "    VALID_DATA_SET_ANN_FILE_PATH,\n",
        "    VALID_DATA_SET_IMAGES_DIR_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR8ha4EHCkA-"
      },
      "outputs": [],
      "source": [
        "#Confirm the dataset was correctly registered\n",
        "[\n",
        "    data_set\n",
        "    for data_set\n",
        "    in MetadataCatalog.list()\n",
        "    if data_set.startswith(DATA_SET_NAME)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krCm2L_lNC83"
      },
      "outputs": [],
      "source": [
        "#Configuring model parameters\n",
        "# HYPERPARAMETERS\n",
        "ARCHITECTURE = \"pointrend_rcnn_X_101_32x8d_FPN_3x_coco\"\n",
        "CONFIG_FILE_PATH = f\"detectron2_repo/projects/PointRend/configs/InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# OUTPUT DIR\n",
        "\n",
        "OUTPUT_DIR_PATH = os.path.join(\n",
        "    DATA_SET_NAME,\n",
        "    ARCHITECTURE,\n",
        "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        ")\n",
        "\n",
        "\n",
        "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxQU8JrgOD73"
      },
      "outputs": [],
      "source": [
        "#Configuring model hyperparameters\n",
        "cfg = get_cfg()\n",
        "point_rend.add_pointrend_config(cfg)\n",
        "cfg.merge_from_file(\"detectron2_repo/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_X_101_32x8d_FPN_3x_coco.yaml\")\n",
        "cfg.MODEL.WEIGHTS = \"model_0094999.pth\"\n",
        "#\n",
        "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
        "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.MODEL.DEVICE = \"cuda\"\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "\n",
        "cfg.MODEL.RESNETS.DEFORM_ON_PER_STAGE = [False, True, True, True]  # Enable on res3, res4, res5\n",
        "cfg.MODEL.RESNETS.DEFORM_MODULATED = True  # Uses flexible receptive fields\n",
        "cfg.MODEL.RESNETS.DEFORM_NUM_GROUPS = 8  # Improves feature extraction\n",
        "\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # Lower LR for fine-tuning\n",
        "cfg.SOLVER.MAX_ITER = 120000  # Train for more iterations\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"  # Gradual learning rate decay\n",
        "cfg.SOLVER.WARMUP_ITERS = 2000\n",
        "\n",
        "cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]  # Use all feature levels\n",
        "cfg.MODEL.FPN.OUT_CHANNELS = 256\n",
        "\n",
        "cfg.MODEL.POINT_HEAD.NUM_SUBDIVISION_POINTS = 4096  # Higher sampling density\n",
        "cfg.MODEL.POINT_HEAD.NUM_SUBDIVISION_STEPS = 4\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES + 1\n",
        "cfg.MODEL.POINT_HEAD.NUM_CLASSES = NUM_CLASSES + 1\n",
        "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7S8y2W2AQvJq"
      },
      "outputs": [],
      "source": [
        "#Train model\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2XMPKQ28GRna"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $OUTPUT_DIR_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsByFDFbQwLi"
      },
      "outputs": [],
      "source": [
        "# Setup model predictor\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hmAcBbpXX-Rh"
      },
      "outputs": [],
      "source": [
        "# Run model on test image\n",
        "TEST_PATH = \"<Include your test image path here>\"\n",
        "img = cv2.imread(TEST_PATH)\n",
        "resized_image = cv2.resize(img, (1280, 1280))\n",
        "cv2_imshow(resized_image)\n",
        "outputs = predictor(resized_image)\n",
        "visualizer = Visualizer(\n",
        "    resized_image[:, :, ::-1],\n",
        "    metadata=MetadataCatalog.get(cfg.DATASETS.TRAIN[0]),\n",
        "    scale=0.8,\n",
        "    instance_mode=ColorMode.IMAGE_BW\n",
        ")\n",
        "out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
